{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR with Convolutional Nets, Batch and Self Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import control_flow_ops\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "import numpy as np\n",
    "import time, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images of this size. Note that this differs from the original CIFAR\n",
    "# image size of 32 x 32. If one alters this number, then the entire model\n",
    "# architecture will change and any model would need to be retrained.\n",
    "IMAGE_SIZE = 24\n",
    "\n",
    "# Global constants describing the CIFAR-10 data set.\n",
    "NUM_CLASSES = 10\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "\n",
    "data_dir = os.path.join('data/cifar10_data', 'cifar-10-batches-bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 100\n",
    "batch_size = 128\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cifar10(filename_queue):\n",
    "    \"\"\"Reads and parses examples from CIFAR10 data files.\n",
    "    \n",
    "    Recommendation: if you want N-way read parallelism, call this function\n",
    "    N times.  This will give you N independent Readers reading different\n",
    "    files & positions within those files, which will give better mixing of\n",
    "    examples.\n",
    "    \n",
    "    Args:\n",
    "      filename_queue: A queue of strings with the filenames to read from.\n",
    "      \n",
    "    Returns:\n",
    "      An object representing a single example, with the following fields:\n",
    "        height: number of rows in the result (32)\n",
    "        width: number of columns in the result (32)\n",
    "        depth: number of color channels in the result (3)\n",
    "        key: a scalar string Tensor describing the filename & record number\n",
    "          for this example.\n",
    "        label: an int32 Tensor with the label in the range 0..9.\n",
    "        uint8image: a [height, width, depth] uint8 Tensor with the image data\n",
    "    \"\"\"\n",
    "\n",
    "    class CIFAR10Record(object):\n",
    "        pass\n",
    "    result = CIFAR10Record()\n",
    "\n",
    "    # Dimensions of the images in the CIFAR-10 dataset.\n",
    "    # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "    # input format.\n",
    "    label_bytes = 1  # 2 for CIFAR-100\n",
    "    result.height = 32\n",
    "    result.width = 32\n",
    "    result.depth = 3\n",
    "    image_bytes = result.height * result.width * result.depth\n",
    "    # Every record consists of a label followed by the image, with a\n",
    "    # fixed number of bytes for each.\n",
    "    record_bytes = label_bytes + image_bytes\n",
    "\n",
    "    # Read a record, getting filenames from the filename_queue.  No\n",
    "    # header or footer in the CIFAR-10 format, so we leave header_bytes\n",
    "    # and footer_bytes at their default of 0.\n",
    "    reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n",
    "    result.key, value = reader.read(filename_queue)\n",
    "\n",
    "    # Convert from a string to a vector of uint8 that is record_bytes long.\n",
    "    record_bytes = tf.decode_raw(value, tf.uint8)\n",
    "\n",
    "    # The first bytes represent the label, which we convert from uint8->int32.\n",
    "    result.label = tf.cast(\n",
    "        tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)\n",
    "\n",
    "    # The remaining bytes after the label represent the image, which we reshape\n",
    "    # from [depth * height * width] to [depth, height, width].\n",
    "    depth_major = tf.reshape(\n",
    "        tf.strided_slice(record_bytes, [label_bytes],\n",
    "                         [label_bytes + image_bytes]),\n",
    "        [result.depth, result.height, result.width])\n",
    "    # Convert from [depth, height, width] to [height, width, depth].\n",
    "    result.uint8image = tf.transpose(depth_major, [1, 2, 0])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_image_and_label_batch(image, label, min_queue_examples, batch_size, shuffle):\n",
    "    \"\"\"Construct a queued batch of images and labels.\n",
    "    \n",
    "    Args:\n",
    "      image: 3-D Tensor of [height, width, 3] of type.float32.\n",
    "      label: 1-D Tensor of type.int32\n",
    "      min_queue_examples: int32, minimum number of samples to retain\n",
    "      in the queue that provides of batches of examples.\n",
    "      batch_size: Number of images per batch.\n",
    "      \n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, height, width, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    # Create a queue that shuffles the examples, and then\n",
    "    # read 'batch_size' images + labels from the example queue.\n",
    "    num_preprocess_threads = 16\n",
    "    if shuffle:\n",
    "        images, label_batch = tf.train.shuffle_batch(\n",
    "            [image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size,\n",
    "            min_after_dequeue=min_queue_examples)\n",
    "    else:\n",
    "        images, label_batch = tf.train.batch(\n",
    "            [image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "    # Display the training images in the visualizer.\n",
    "    tf.summary.image('images', images)\n",
    "\n",
    "    return images, tf.reshape(label_batch, [batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distorted_inputs(data_dir, batch_size):\n",
    "    \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "    Args:\n",
    "      data_dir: Path to the CIFAR-10 data directory.\n",
    "      batch_size: Number of images per batch.\n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "\n",
    "    filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i) \n",
    "                 for i in range(1, 6)]\n",
    "    for f in filenames:\n",
    "        if not tf.gfile.Exists(f):\n",
    "            raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "    # Create a queue that produces the filenames to read.\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "    # Read examples from files in the filename queue.\n",
    "    read_input = read_cifar10(filename_queue)\n",
    "    reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "    \n",
    "    height = IMAGE_SIZE\n",
    "    width = IMAGE_SIZE\n",
    "\n",
    "    # Image processing for training the network. Note the many random\n",
    "    # distortions applied to the image.\n",
    "\n",
    "    # Randomly crop a [height, width] section of the image.\n",
    "    distorted_image = tf.random_crop(reshaped_image, size=[height, width, 3])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "\n",
    "    # Because these operations are not commutative, consider randomizing\n",
    "    # randomize the order their operation.\n",
    "    distorted_image = tf.image.random_brightness(distorted_image, max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(distorted_image, lower=0.2, upper=1.8)\n",
    "\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    float_image = tf.image.per_image_standardization(distorted_image)\n",
    "    \n",
    "    # Set the shapes of tensors.\n",
    "    float_image.set_shape([height, width, 3])\n",
    "    read_input.label.set_shape([1])\n",
    "\n",
    "    # Ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN *\n",
    "                           min_fraction_of_examples_in_queue)\n",
    "    print ('Filling queue with %d CIFAR images before starting to train. '\n",
    "           'This will take a few minutes.' % min_queue_examples)\n",
    "\n",
    "    # Generate a batch of images and labels by building up a queue of examples.\n",
    "    return _generate_image_and_label_batch(float_image, read_input.label, min_queue_examples,\n",
    "                                           batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs(eval_data, data_dir, batch_size):\n",
    "    \"\"\"Construct input for CIFAR evaluation using the Reader ops.\n",
    "    Args:\n",
    "      eval_data: bool, indicating if one should use the train or eval data set.\n",
    "      data_dir: Path to the CIFAR-10 data directory.\n",
    "      batch_size: Number of images per batch.\n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    if not eval_data:\n",
    "        filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in xrange(1, 6)]\n",
    "        num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN\n",
    "    else:\n",
    "        filenames = [os.path.join(data_dir, 'test_batch.bin')]\n",
    "        num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_EVAL\n",
    "\n",
    "    for f in filenames:\n",
    "        if not tf.gfile.Exists(f):\n",
    "            raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "    with tf.name_scope('input'):\n",
    "        # Create a queue that produces the filenames to read.\n",
    "        filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "        # Read examples from files in the filename queue.\n",
    "        read_input = read_cifar10(filename_queue)\n",
    "        reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "\n",
    "        height = IMAGE_SIZE\n",
    "        width = IMAGE_SIZE\n",
    "\n",
    "        # Image processing for evaluation.\n",
    "        # Crop the central [height, width] of the image.\n",
    "        resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image, height, width)\n",
    "\n",
    "        # Subtract off the mean and divide by the variance of the pixels.\n",
    "        float_image = tf.image.per_image_standardization(resized_image)\n",
    "\n",
    "        # Set the shapes of tensors.\n",
    "        float_image.set_shape([height, width, 3])\n",
    "        read_input.label.set_shape([1])\n",
    "\n",
    "        # Ensure that the random shuffling has good mixing properties.\n",
    "        min_fraction_of_examples_in_queue = 0.4\n",
    "        min_queue_examples = int(num_examples_per_epoch * min_fraction_of_examples_in_queue)\n",
    "\n",
    "    # Generate a batch of images and labels by building up a queue of examples.\n",
    "    return _generate_image_and_label_batch(float_image, read_input.label, min_queue_examples,\n",
    "                                           batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_batch_norm(x, n_out, phase_train):\n",
    "    beta_init = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
    "    gamma_init = tf.constant_initializer(value=1.0, dtype=tf.float32)\n",
    "\n",
    "    beta = tf.get_variable(\"beta\", [n_out], initializer=beta_init)\n",
    "    gamma = tf.get_variable(\"gamma\", [n_out], initializer=gamma_init)\n",
    "\n",
    "    batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
    "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
    "    def mean_var_with_update():\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "    mean, var = control_flow_ops.cond(phase_train,\n",
    "        mean_var_with_update,\n",
    "        lambda: (ema_mean, ema_var))\n",
    "\n",
    "    normed = tf.nn.batch_norm_with_global_normalization(x, mean, var,\n",
    "        beta, gamma, 1e-3, True)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_batch_norm(x, n_out, phase_train):\n",
    "    beta_init = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
    "    gamma_init = tf.constant_initializer(value=1.0, dtype=tf.float32)\n",
    "\n",
    "    beta = tf.get_variable(\"beta\", [n_out], initializer=beta_init)\n",
    "    gamma = tf.get_variable(\"gamma\", [n_out], initializer=gamma_init)\n",
    "\n",
    "    batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
    "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
    "    def mean_var_with_update():\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "    mean, var = control_flow_ops.cond(phase_train,\n",
    "        mean_var_with_update,\n",
    "        lambda: (ema_mean, ema_var))\n",
    "\n",
    "    reshaped_x = tf.reshape(x, [-1, 1, 1, n_out])\n",
    "    normed = tf.nn.batch_norm_with_global_normalization(reshaped_x, mean, var,\n",
    "        beta, gamma, 1e-3, True)\n",
    "    return tf.reshape(normed, [-1, n_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_summary(V, weight_shape):\n",
    "    ix = weight_shape[0]\n",
    "    iy = weight_shape[1]\n",
    "    cx, cy = 8, 8\n",
    "    V_T = tf.transpose(V, (3, 0, 1, 2))\n",
    "    tf.summary.image(\"filters\", V_T, max_outputs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input, weight_shape, bias_shape, phase_train, visualize=False):\n",
    "    incoming = weight_shape[0] * weight_shape[1] * weight_shape[2]\n",
    "    weight_init = tf.random_normal_initializer(stddev=np.sqrt(1 / incoming))\n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
    "    if visualize:\n",
    "        filter_summary(W, weight_shape)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
    "    logits = tf.nn.bias_add(tf.nn.conv2d(input, W, strides=[1, 1, 1, 1], padding='SAME'), b)\n",
    "    return tf.nn.selu(conv_batch_norm(logits, weight_shape[3], phase_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(input, k=2):\n",
    "    return tf.nn.max_pool(input, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(input, weight_shape, bias_shape, phase_train):\n",
    "    weight_stddev = np.sqrt(1 / weight_shape[0])\n",
    "    w_init = tf.random_normal_initializer(stddev=weight_stddev)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=w_init)\n",
    "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
    "    logits = tf.matmul(input, W) + b\n",
    "    return tf.nn.selu(layer_batch_norm(logits, weight_shape[1], phase_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x, keep_prob, phase_train):\n",
    "\n",
    "    with tf.variable_scope(\"conv_1\"):\n",
    "        conv_1 = conv2d(x, [5, 5, 3, 64], [64], phase_train, visualize=True)\n",
    "        pool_1 = max_pool(conv_1)\n",
    "\n",
    "    with tf.variable_scope(\"conv_2\"):\n",
    "        conv_2 = conv2d(pool_1, [5, 5, 64, 64], [64], phase_train)\n",
    "        pool_2 = max_pool(conv_2)\n",
    "\n",
    "    with tf.variable_scope(\"fc_1\"):\n",
    "\n",
    "        dim = 1\n",
    "        for d in pool_2.get_shape()[1:].as_list():\n",
    "            dim *= d\n",
    "\n",
    "        pool_2_flat = tf.reshape(pool_2, [-1, dim])\n",
    "        fc_1 = layer(pool_2_flat, [dim, 384], [384], phase_train)\n",
    "        \n",
    "        # apply dropout\n",
    "        fc_1_drop = tf.nn.dropout(fc_1, keep_prob)\n",
    "\n",
    "    with tf.variable_scope(\"fc_2\"):\n",
    "\n",
    "        fc_2 = layer(fc_1_drop, [384, 192], [192], phase_train)\n",
    "        \n",
    "        # apply dropout\n",
    "        fc_2_drop = tf.nn.dropout(fc_2, keep_prob)\n",
    "\n",
    "    with tf.variable_scope(\"output\"):\n",
    "        output = layer(fc_2_drop, [192, 10], [10], phase_train)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(output, y):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=tf.cast(y, tf.int64))\n",
    "    loss = tf.reduce_mean(xentropy)    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(output, y):\n",
    "    correct_prediction = tf.equal(tf.cast(tf.argmax(output, 1), dtype=tf.int32), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"validation error\", (1.0 - accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "INFO:tensorflow:Summary name validation error is illegal; using validation_error instead.\n",
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
      "Epoch: 0001 cost = 1.594707664\n",
      "Validation Error: 0.4765625\n",
      "Epoch: 0002 cost = 1.286430845\n",
      "Validation Error: 0.453125\n",
      "Epoch: 0003 cost = 1.135211200\n",
      "Validation Error: 0.28125\n",
      "Epoch: 0004 cost = 1.050288937\n",
      "Validation Error: 0.3125\n",
      "Epoch: 0005 cost = 0.980878689\n",
      "Validation Error: 0.3359375\n",
      "Epoch: 0006 cost = 0.927126494\n",
      "Validation Error: 0.2265625\n",
      "Epoch: 0007 cost = 0.878245339\n",
      "Validation Error: 0.2578125\n",
      "Epoch: 0008 cost = 0.845558573\n",
      "Validation Error: 0.2890625\n",
      "Epoch: 0009 cost = 0.822817763\n",
      "Validation Error: 0.2109375\n",
      "Epoch: 0010 cost = 0.787413510\n",
      "Validation Error: 0.203125\n",
      "Epoch: 0011 cost = 0.770079235\n",
      "Validation Error: 0.234375\n",
      "Epoch: 0012 cost = 0.749628478\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0013 cost = 0.722935063\n",
      "Validation Error: 0.2265625\n",
      "Epoch: 0014 cost = 0.705862846\n",
      "Validation Error: 0.25\n",
      "Epoch: 0015 cost = 0.700490485\n",
      "Validation Error: 0.234375\n",
      "Epoch: 0016 cost = 0.677986863\n",
      "Validation Error: 0.2109375\n",
      "Epoch: 0017 cost = 0.666574914\n",
      "Validation Error: 0.15625\n",
      "Epoch: 0018 cost = 0.655004626\n",
      "Validation Error: 0.1796875\n",
      "Epoch: 0019 cost = 0.648488753\n",
      "Validation Error: 0.2109375\n",
      "Epoch: 0020 cost = 0.633254170\n",
      "Validation Error: 0.2421875\n",
      "Epoch: 0021 cost = 0.617599890\n",
      "Validation Error: 0.21875\n",
      "Epoch: 0022 cost = 0.610124991\n",
      "Validation Error: 0.1875\n",
      "Epoch: 0023 cost = 0.605440745\n",
      "Validation Error: 0.1328125\n",
      "Epoch: 0024 cost = 0.592470780\n",
      "Validation Error: 0.2265625\n",
      "Epoch: 0025 cost = 0.574521994\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0026 cost = 0.570928185\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0027 cost = 0.562202431\n",
      "Validation Error: 0.1875\n",
      "Epoch: 0028 cost = 0.558010468\n",
      "Validation Error: 0.1875\n",
      "Epoch: 0029 cost = 0.552898859\n",
      "Validation Error: 0.140625\n",
      "Epoch: 0030 cost = 0.535102200\n",
      "Validation Error: 0.1875\n",
      "Epoch: 0031 cost = 0.531944202\n",
      "Validation Error: 0.15625\n",
      "Epoch: 0032 cost = 0.522033107\n",
      "Validation Error: 0.15625\n",
      "Epoch: 0033 cost = 0.522976442\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0034 cost = 0.513286659\n",
      "Validation Error: 0.2421875\n",
      "Epoch: 0035 cost = 0.506324337\n",
      "Validation Error: 0.15625\n",
      "Epoch: 0036 cost = 0.501887204\n",
      "Validation Error: 0.1484375\n",
      "Epoch: 0037 cost = 0.493953969\n",
      "Validation Error: 0.1953125\n",
      "Epoch: 0038 cost = 0.487104613\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0039 cost = 0.479642044\n",
      "Validation Error: 0.2265625\n",
      "Epoch: 0040 cost = 0.475282910\n",
      "Validation Error: 0.1328125\n",
      "Epoch: 0041 cost = 0.481146526\n",
      "Validation Error: 0.1875\n",
      "Epoch: 0042 cost = 0.461944567\n",
      "Validation Error: 0.125\n",
      "Epoch: 0043 cost = 0.459695932\n",
      "Validation Error: 0.234375\n",
      "Epoch: 0044 cost = 0.461629512\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0045 cost = 0.454756653\n",
      "Validation Error: 0.15625\n",
      "Epoch: 0046 cost = 0.448816565\n",
      "Validation Error: 0.1015625\n",
      "Epoch: 0047 cost = 0.446009803\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0048 cost = 0.440376779\n",
      "Validation Error: 0.234375\n",
      "Epoch: 0049 cost = 0.440750400\n",
      "Validation Error: 0.21875\n",
      "Epoch: 0050 cost = 0.430071512\n",
      "Validation Error: 0.15625\n",
      "Epoch: 0051 cost = 0.432078472\n",
      "Validation Error: 0.125\n",
      "Epoch: 0052 cost = 0.431881307\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0053 cost = 0.420639203\n",
      "Validation Error: 0.2109375\n",
      "Epoch: 0054 cost = 0.429401564\n",
      "Validation Error: 0.15625\n",
      "Epoch: 0055 cost = 0.412233858\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0056 cost = 0.408303170\n",
      "Validation Error: 0.140625\n",
      "Epoch: 0057 cost = 0.410105328\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0058 cost = 0.407755856\n",
      "Validation Error: 0.1875\n",
      "Epoch: 0059 cost = 0.394583346\n",
      "Validation Error: 0.1953125\n",
      "Epoch: 0060 cost = 0.396456863\n",
      "Validation Error: 0.2265625\n",
      "Epoch: 0061 cost = 0.395760694\n",
      "Validation Error: 0.140625\n",
      "Epoch: 0062 cost = 0.397240591\n",
      "Validation Error: 0.15625\n",
      "Epoch: 0063 cost = 0.383692923\n",
      "Validation Error: 0.1484375\n",
      "Epoch: 0064 cost = 0.388004610\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0065 cost = 0.379111253\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0066 cost = 0.384668941\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0067 cost = 0.379308348\n",
      "Validation Error: 0.1953125\n",
      "Epoch: 0068 cost = 0.377675124\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0069 cost = 0.368684280\n",
      "Validation Error: 0.140625\n",
      "Epoch: 0070 cost = 0.365852347\n",
      "Validation Error: 0.140625\n",
      "Epoch: 0071 cost = 0.364669513\n",
      "Validation Error: 0.203125\n",
      "Epoch: 0072 cost = 0.359962388\n",
      "Validation Error: 0.140625\n",
      "Epoch: 0073 cost = 0.368534562\n",
      "Validation Error: 0.1953125\n",
      "Epoch: 0074 cost = 0.364656924\n",
      "Validation Error: 0.1953125\n",
      "Epoch: 0075 cost = 0.352447804\n",
      "Validation Error: 0.140625\n",
      "Epoch: 0076 cost = 0.353760063\n",
      "Validation Error: 0.1484375\n",
      "Epoch: 0077 cost = 0.349861673\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0078 cost = 0.349348581\n",
      "Validation Error: 0.203125\n",
      "Epoch: 0079 cost = 0.339399571\n",
      "Validation Error: 0.140625\n",
      "Epoch: 0080 cost = 0.351062094\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0081 cost = 0.342278138\n",
      "Validation Error: 0.078125\n",
      "Epoch: 0082 cost = 0.341574274\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0083 cost = 0.336130838\n",
      "Validation Error: 0.1015625\n",
      "Epoch: 0084 cost = 0.335365360\n",
      "Validation Error: 0.09375\n",
      "Epoch: 0085 cost = 0.341700340\n",
      "Validation Error: 0.0859375\n",
      "Epoch: 0086 cost = 0.334977997\n",
      "Validation Error: 0.203125\n",
      "Epoch: 0087 cost = 0.331471013\n",
      "Validation Error: 0.1484375\n",
      "Epoch: 0088 cost = 0.325348213\n",
      "Validation Error: 0.1953125\n",
      "Epoch: 0089 cost = 0.323593443\n",
      "Validation Error: 0.1484375\n",
      "Epoch: 0090 cost = 0.319556967\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0091 cost = 0.323664817\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0092 cost = 0.323158756\n",
      "Validation Error: 0.140625\n",
      "Epoch: 0093 cost = 0.319682980\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0094 cost = 0.318748288\n",
      "Validation Error: 0.1484375\n",
      "Epoch: 0095 cost = 0.314889189\n",
      "Validation Error: 0.1328125\n",
      "Epoch: 0096 cost = 0.313120184\n",
      "Validation Error: 0.1171875\n",
      "Epoch: 0097 cost = 0.311415211\n",
      "Validation Error: 0.140625\n",
      "Epoch: 0098 cost = 0.300509357\n",
      "Validation Error: 0.2109375\n",
      "Epoch: 0099 cost = 0.309943746\n",
      "Validation Error: 0.1796875\n",
      "Epoch: 0100 cost = 0.307811324\n",
      "Validation Error: 0.1484375\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.859375\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "\n",
    "        with tf.Graph().as_default():\n",
    "\n",
    "            with tf.variable_scope(\"cifar_conv_bn-snn_model\"):\n",
    "\n",
    "                x = tf.placeholder(\"float\", [None, 24, 24, 3])\n",
    "                y = tf.placeholder(\"int32\", [None])\n",
    "                keep_prob = tf.placeholder(tf.float32) # dropout probability\n",
    "                phase_train = tf.placeholder(tf.bool) # training or testing\n",
    "\n",
    "                distorted_images, distorted_labels = distorted_inputs(data_dir, batch_size)\n",
    "                val_images, val_labels = inputs(True, data_dir, batch_size)\n",
    "\n",
    "                output = inference(x, keep_prob, phase_train)\n",
    "\n",
    "                cost = loss(output, y)\n",
    "\n",
    "                global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "                train_op = training(cost, global_step)\n",
    "\n",
    "                eval_op = evaluate(output, y)\n",
    "\n",
    "                summary_op = tf.summary.merge_all()\n",
    "\n",
    "                saver = tf.train.Saver()\n",
    "\n",
    "                sess = tf.Session()\n",
    "\n",
    "                summary_writer = tf.summary.FileWriter(\"conv_cifar_bn-snn_logs/\",\n",
    "                                                       graph_def=sess.graph_def)\n",
    "\n",
    "                \n",
    "                init_op = tf.global_variables_initializer()\n",
    "\n",
    "                sess.run(init_op)\n",
    "                \n",
    "                tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "                # Training cycle\n",
    "                for epoch in range(training_epochs):\n",
    "                    \n",
    "                    avg_cost = 0.\n",
    "                    total_batch = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN/batch_size)\n",
    "                    # Loop over all batches\n",
    "                    for i in range(total_batch):\n",
    "                        # Fit training using batch data\n",
    "                        \n",
    "                        train_x, train_y = sess.run([distorted_images, distorted_labels])\n",
    "                        \n",
    "                        _, new_cost = sess.run([train_op, cost], feed_dict={x: train_x, y: train_y,\n",
    "                                                                            keep_prob: 1,\n",
    "                                                                            phase_train: True})                                            \n",
    "                        # Compute average loss\n",
    "                        avg_cost += new_cost/total_batch\n",
    "                             \n",
    "                    # Display logs per epoch step\n",
    "                    if epoch % display_step == 0:\n",
    "                        print(\"Epoch:\", '%04d' % (epoch+1), \"cost =\", \"{:.9f}\".format(avg_cost))\n",
    "                        \n",
    "                        val_x, val_y = sess.run([val_images, val_labels])\n",
    "                        \n",
    "                        accuracy = sess.run(eval_op, feed_dict={x: val_x, y: val_y,\n",
    "                                                                keep_prob: 1,\n",
    "                                                                phase_train: False})\n",
    "\n",
    "                        print(\"Validation Error:\", (1 - accuracy))\n",
    "\n",
    "                        summary_str = sess.run(summary_op, feed_dict={x: train_x, y: train_y,\n",
    "                                                                      keep_prob: 1,\n",
    "                                                                      phase_train: False})\n",
    "                        summary_writer.add_summary(summary_str, sess.run(global_step))\n",
    "\n",
    "                        saver.save(sess, \"conv_cifar_bn-snn_logs/model-checkpoint\", global_step=global_step)\n",
    "                        \n",
    "                print(\"Optimization Finished!\")\n",
    "                \n",
    "                val_x, val_y = sess.run([val_images, val_labels])\n",
    "                accuracy = sess.run(eval_op, feed_dict={x: val_x, y: val_y,\n",
    "                                                        keep_prob: 1,\n",
    "                                                        phase_train: False})\n",
    "\n",
    "                print(\"Test Accuracy:\", accuracy)\n",
    "                        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
