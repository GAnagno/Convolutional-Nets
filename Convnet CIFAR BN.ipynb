{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with Convolutional Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import control_flow_ops\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "import numpy as np\n",
    "import time, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images of this size. Note that this differs from the original CIFAR\n",
    "# image size of 32 x 32. If one alters this number, then the entire model\n",
    "# architecture will change and any model would need to be retrained.\n",
    "IMAGE_SIZE = 24\n",
    "\n",
    "# Global constants describing the CIFAR-10 data set.\n",
    "NUM_CLASSES = 10\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "\n",
    "data_dir = os.path.join('data/cifar10_data', 'cifar-10-batches-bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 100\n",
    "batch_size = 128\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cifar10(filename_queue):\n",
    "    \"\"\"Reads and parses examples from CIFAR10 data files.\n",
    "    \n",
    "    Recommendation: if you want N-way read parallelism, call this function\n",
    "    N times.  This will give you N independent Readers reading different\n",
    "    files & positions within those files, which will give better mixing of\n",
    "    examples.\n",
    "    \n",
    "    Args:\n",
    "      filename_queue: A queue of strings with the filenames to read from.\n",
    "      \n",
    "    Returns:\n",
    "      An object representing a single example, with the following fields:\n",
    "        height: number of rows in the result (32)\n",
    "        width: number of columns in the result (32)\n",
    "        depth: number of color channels in the result (3)\n",
    "        key: a scalar string Tensor describing the filename & record number\n",
    "          for this example.\n",
    "        label: an int32 Tensor with the label in the range 0..9.\n",
    "        uint8image: a [height, width, depth] uint8 Tensor with the image data\n",
    "    \"\"\"\n",
    "\n",
    "    class CIFAR10Record(object):\n",
    "        pass\n",
    "    result = CIFAR10Record()\n",
    "\n",
    "    # Dimensions of the images in the CIFAR-10 dataset.\n",
    "    # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "    # input format.\n",
    "    label_bytes = 1  # 2 for CIFAR-100\n",
    "    result.height = 32\n",
    "    result.width = 32\n",
    "    result.depth = 3\n",
    "    image_bytes = result.height * result.width * result.depth\n",
    "    # Every record consists of a label followed by the image, with a\n",
    "    # fixed number of bytes for each.\n",
    "    record_bytes = label_bytes + image_bytes\n",
    "\n",
    "    # Read a record, getting filenames from the filename_queue.  No\n",
    "    # header or footer in the CIFAR-10 format, so we leave header_bytes\n",
    "    # and footer_bytes at their default of 0.\n",
    "    reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n",
    "    result.key, value = reader.read(filename_queue)\n",
    "\n",
    "    # Convert from a string to a vector of uint8 that is record_bytes long.\n",
    "    record_bytes = tf.decode_raw(value, tf.uint8)\n",
    "\n",
    "    # The first bytes represent the label, which we convert from uint8->int32.\n",
    "    result.label = tf.cast(\n",
    "        tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)\n",
    "\n",
    "    # The remaining bytes after the label represent the image, which we reshape\n",
    "    # from [depth * height * width] to [depth, height, width].\n",
    "    depth_major = tf.reshape(\n",
    "        tf.strided_slice(record_bytes, [label_bytes],\n",
    "                         [label_bytes + image_bytes]),\n",
    "        [result.depth, result.height, result.width])\n",
    "    # Convert from [depth, height, width] to [height, width, depth].\n",
    "    result.uint8image = tf.transpose(depth_major, [1, 2, 0])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_image_and_label_batch(image, label, min_queue_examples, batch_size, shuffle):\n",
    "    \"\"\"Construct a queued batch of images and labels.\n",
    "    \n",
    "    Args:\n",
    "      image: 3-D Tensor of [height, width, 3] of type.float32.\n",
    "      label: 1-D Tensor of type.int32\n",
    "      min_queue_examples: int32, minimum number of samples to retain\n",
    "      in the queue that provides of batches of examples.\n",
    "      batch_size: Number of images per batch.\n",
    "      \n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, height, width, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    # Create a queue that shuffles the examples, and then\n",
    "    # read 'batch_size' images + labels from the example queue.\n",
    "    num_preprocess_threads = 16\n",
    "    if shuffle:\n",
    "        images, label_batch = tf.train.shuffle_batch(\n",
    "            [image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size,\n",
    "            min_after_dequeue=min_queue_examples)\n",
    "    else:\n",
    "        images, label_batch = tf.train.batch(\n",
    "            [image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "    # Display the training images in the visualizer.\n",
    "    tf.summary.image('images', images)\n",
    "\n",
    "    return images, tf.reshape(label_batch, [batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distorted_inputs(data_dir, batch_size):\n",
    "    \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "    Args:\n",
    "      data_dir: Path to the CIFAR-10 data directory.\n",
    "      batch_size: Number of images per batch.\n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "\n",
    "    filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i) \n",
    "                 for i in range(1, 6)]\n",
    "    for f in filenames:\n",
    "        if not tf.gfile.Exists(f):\n",
    "            raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "    # Create a queue that produces the filenames to read.\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "    # Read examples from files in the filename queue.\n",
    "    read_input = read_cifar10(filename_queue)\n",
    "    reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "    \n",
    "    height = IMAGE_SIZE\n",
    "    width = IMAGE_SIZE\n",
    "\n",
    "    # Image processing for training the network. Note the many random\n",
    "    # distortions applied to the image.\n",
    "\n",
    "    # Randomly crop a [height, width] section of the image.\n",
    "    distorted_image = tf.random_crop(reshaped_image, size=[height, width, 3])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "\n",
    "    # Because these operations are not commutative, consider randomizing\n",
    "    # randomize the order their operation.\n",
    "    distorted_image = tf.image.random_brightness(distorted_image, max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(distorted_image, lower=0.2, upper=1.8)\n",
    "\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    float_image = tf.image.per_image_standardization(distorted_image)\n",
    "    \n",
    "    # Set the shapes of tensors.\n",
    "    float_image.set_shape([height, width, 3])\n",
    "    read_input.label.set_shape([1])\n",
    "\n",
    "    # Ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN *\n",
    "                           min_fraction_of_examples_in_queue)\n",
    "    print ('Filling queue with %d CIFAR images before starting to train. '\n",
    "           'This will take a few minutes.' % min_queue_examples)\n",
    "\n",
    "    # Generate a batch of images and labels by building up a queue of examples.\n",
    "    return _generate_image_and_label_batch(float_image, read_input.label, min_queue_examples,\n",
    "                                           batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs(eval_data, data_dir, batch_size):\n",
    "    \"\"\"Construct input for CIFAR evaluation using the Reader ops.\n",
    "    Args:\n",
    "      eval_data: bool, indicating if one should use the train or eval data set.\n",
    "      data_dir: Path to the CIFAR-10 data directory.\n",
    "      batch_size: Number of images per batch.\n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    if not eval_data:\n",
    "        filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in xrange(1, 6)]\n",
    "        num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN\n",
    "    else:\n",
    "        filenames = [os.path.join(data_dir, 'test_batch.bin')]\n",
    "        num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_EVAL\n",
    "\n",
    "    for f in filenames:\n",
    "        if not tf.gfile.Exists(f):\n",
    "            raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "    with tf.name_scope('input'):\n",
    "        # Create a queue that produces the filenames to read.\n",
    "        filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "        # Read examples from files in the filename queue.\n",
    "        read_input = read_cifar10(filename_queue)\n",
    "        reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "\n",
    "        height = IMAGE_SIZE\n",
    "        width = IMAGE_SIZE\n",
    "\n",
    "        # Image processing for evaluation.\n",
    "        # Crop the central [height, width] of the image.\n",
    "        resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image, height, width)\n",
    "\n",
    "        # Subtract off the mean and divide by the variance of the pixels.\n",
    "        float_image = tf.image.per_image_standardization(resized_image)\n",
    "\n",
    "        # Set the shapes of tensors.\n",
    "        float_image.set_shape([height, width, 3])\n",
    "        read_input.label.set_shape([1])\n",
    "\n",
    "        # Ensure that the random shuffling has good mixing properties.\n",
    "        min_fraction_of_examples_in_queue = 0.4\n",
    "        min_queue_examples = int(num_examples_per_epoch * min_fraction_of_examples_in_queue)\n",
    "\n",
    "    # Generate a batch of images and labels by building up a queue of examples.\n",
    "    return _generate_image_and_label_batch(float_image, read_input.label, min_queue_examples,\n",
    "                                           batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_batch_norm(x, n_out, phase_train):\n",
    "    beta_init = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
    "    gamma_init = tf.constant_initializer(value=1.0, dtype=tf.float32)\n",
    "\n",
    "    beta = tf.get_variable(\"beta\", [n_out], initializer=beta_init)\n",
    "    gamma = tf.get_variable(\"gamma\", [n_out], initializer=gamma_init)\n",
    "\n",
    "    batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
    "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
    "    def mean_var_with_update():\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "    mean, var = control_flow_ops.cond(phase_train,\n",
    "        mean_var_with_update,\n",
    "        lambda: (ema_mean, ema_var))\n",
    "\n",
    "    normed = tf.nn.batch_norm_with_global_normalization(x, mean, var,\n",
    "        beta, gamma, 1e-3, True)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_batch_norm(x, n_out, phase_train):\n",
    "    beta_init = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
    "    gamma_init = tf.constant_initializer(value=1.0, dtype=tf.float32)\n",
    "\n",
    "    beta = tf.get_variable(\"beta\", [n_out], initializer=beta_init)\n",
    "    gamma = tf.get_variable(\"gamma\", [n_out], initializer=gamma_init)\n",
    "\n",
    "    batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
    "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
    "    def mean_var_with_update():\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "    mean, var = control_flow_ops.cond(phase_train,\n",
    "        mean_var_with_update,\n",
    "        lambda: (ema_mean, ema_var))\n",
    "\n",
    "    reshaped_x = tf.reshape(x, [-1, 1, 1, n_out])\n",
    "    normed = tf.nn.batch_norm_with_global_normalization(reshaped_x, mean, var,\n",
    "        beta, gamma, 1e-3, True)\n",
    "    return tf.reshape(normed, [-1, n_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_summary(V, weight_shape):\n",
    "    ix = weight_shape[0]\n",
    "    iy = weight_shape[1]\n",
    "    cx, cy = 8, 8\n",
    "    V_T = tf.transpose(V, (3, 0, 1, 2))\n",
    "    tf.summary.image(\"filters\", V_T, max_outputs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input, weight_shape, bias_shape, phase_train, visualize=False):\n",
    "    incoming = weight_shape[0] * weight_shape[1] * weight_shape[2]\n",
    "    weight_init = tf.random_normal_initializer(stddev=(2.0/incoming)**0.5)\n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
    "    if visualize:\n",
    "        filter_summary(W, weight_shape)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
    "    logits = tf.nn.bias_add(tf.nn.conv2d(input, W, strides=[1, 1, 1, 1], padding='SAME'), b)\n",
    "    return tf.nn.relu(conv_batch_norm(logits, weight_shape[3], phase_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(input, k=2):\n",
    "    return tf.nn.max_pool(input, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(input, weight_shape, bias_shape, phase_train):\n",
    "    weight_stddev = (2.0/weight_shape[0])**0.5\n",
    "    w_init = tf.random_normal_initializer(stddev=weight_stddev)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=w_init)\n",
    "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
    "    logits = tf.matmul(input, W) + b\n",
    "    return tf.nn.relu(layer_batch_norm(logits, weight_shape[1], phase_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x, keep_prob, phase_train):\n",
    "\n",
    "    with tf.variable_scope(\"conv_1\"):\n",
    "        conv_1 = conv2d(x, [5, 5, 3, 64], [64], phase_train, visualize=True)\n",
    "        pool_1 = max_pool(conv_1)\n",
    "\n",
    "    with tf.variable_scope(\"conv_2\"):\n",
    "        conv_2 = conv2d(pool_1, [5, 5, 64, 64], [64], phase_train)\n",
    "        pool_2 = max_pool(conv_2)\n",
    "\n",
    "    with tf.variable_scope(\"fc_1\"):\n",
    "\n",
    "        dim = 1\n",
    "        for d in pool_2.get_shape()[1:].as_list():\n",
    "            dim *= d\n",
    "\n",
    "        pool_2_flat = tf.reshape(pool_2, [-1, dim])\n",
    "        fc_1 = layer(pool_2_flat, [dim, 384], [384], phase_train)\n",
    "        \n",
    "        # apply dropout\n",
    "        fc_1_drop = tf.nn.dropout(fc_1, keep_prob)\n",
    "\n",
    "    with tf.variable_scope(\"fc_2\"):\n",
    "\n",
    "        fc_2 = layer(fc_1_drop, [384, 192], [192], phase_train)\n",
    "        \n",
    "        # apply dropout\n",
    "        fc_2_drop = tf.nn.dropout(fc_2, keep_prob)\n",
    "\n",
    "    with tf.variable_scope(\"output\"):\n",
    "        output = layer(fc_2_drop, [192, 10], [10], phase_train)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(output, y):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=tf.cast(y, tf.int64))\n",
    "    loss = tf.reduce_mean(xentropy)    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(output, y):\n",
    "    correct_prediction = tf.equal(tf.cast(tf.argmax(output, 1), dtype=tf.int32), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"validation error\", (1.0 - accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "INFO:tensorflow:Summary name validation error is illegal; using validation_error instead.\n",
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
      "Epoch: 0001 cost = 1.528211777\n",
      "Validation Error: 0.4453125\n",
      "Epoch: 0002 cost = 1.150898066\n",
      "Validation Error: 0.328125\n",
      "Epoch: 0003 cost = 1.015685867\n",
      "Validation Error: 0.296875\n",
      "Epoch: 0004 cost = 0.930645312\n",
      "Validation Error: 0.296875\n",
      "Epoch: 0005 cost = 0.861676842\n",
      "Validation Error: 0.2265625\n",
      "Epoch: 0006 cost = 0.822305337\n",
      "Validation Error: 0.203125\n",
      "Epoch: 0007 cost = 0.791600337\n",
      "Validation Error: 0.1875\n",
      "Epoch: 0008 cost = 0.750455532\n",
      "Validation Error: 0.265625\n",
      "Epoch: 0009 cost = 0.733233618\n",
      "Validation Error: 0.265625\n",
      "Epoch: 0010 cost = 0.705328370\n",
      "Validation Error: 0.25\n",
      "Epoch: 0011 cost = 0.697710543\n",
      "Validation Error: 0.2109375\n",
      "Epoch: 0012 cost = 0.665125645\n",
      "Validation Error: 0.1953125\n",
      "Epoch: 0013 cost = 0.647391130\n",
      "Validation Error: 0.2734375\n",
      "Epoch: 0014 cost = 0.634172785\n",
      "Validation Error: 0.2578125\n",
      "Epoch: 0015 cost = 0.625102354\n",
      "Validation Error: 0.2109375\n",
      "Epoch: 0016 cost = 0.610169169\n",
      "Validation Error: 0.15625\n",
      "Epoch: 0017 cost = 0.607446159\n",
      "Validation Error: 0.1796875\n",
      "Epoch: 0018 cost = 0.582654215\n",
      "Validation Error: 0.140625\n",
      "Epoch: 0019 cost = 0.580015371\n",
      "Validation Error: 0.1875\n",
      "Epoch: 0020 cost = 0.560577752\n",
      "Validation Error: 0.234375\n",
      "Epoch: 0021 cost = 0.556622617\n",
      "Validation Error: 0.203125\n",
      "Epoch: 0022 cost = 0.541391057\n",
      "Validation Error: 0.2109375\n",
      "Epoch: 0023 cost = 0.539304869\n",
      "Validation Error: 0.140625\n",
      "Epoch: 0024 cost = 0.525477845\n",
      "Validation Error: 0.2109375\n",
      "Epoch: 0025 cost = 0.513430877\n",
      "Validation Error: 0.1953125\n",
      "Epoch: 0026 cost = 0.517848744\n",
      "Validation Error: 0.203125\n",
      "Epoch: 0027 cost = 0.502024204\n",
      "Validation Error: 0.2109375\n",
      "Epoch: 0028 cost = 0.504231637\n",
      "Validation Error: 0.2109375\n",
      "Epoch: 0029 cost = 0.487568292\n",
      "Validation Error: 0.1875\n",
      "Epoch: 0030 cost = 0.480186841\n",
      "Validation Error: 0.1953125\n",
      "Epoch: 0031 cost = 0.481108613\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0032 cost = 0.473201788\n",
      "Validation Error: 0.1796875\n",
      "Epoch: 0033 cost = 0.465763606\n",
      "Validation Error: 0.1796875\n",
      "Epoch: 0034 cost = 0.461006571\n",
      "Validation Error: 0.21875\n",
      "Epoch: 0035 cost = 0.459291768\n",
      "Validation Error: 0.140625\n",
      "Epoch: 0036 cost = 0.446538375\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0037 cost = 0.437453889\n",
      "Validation Error: 0.203125\n",
      "Epoch: 0038 cost = 0.438277714\n",
      "Validation Error: 0.1875\n",
      "Epoch: 0039 cost = 0.434511807\n",
      "Validation Error: 0.2421875\n",
      "Epoch: 0040 cost = 0.428140183\n",
      "Validation Error: 0.15625\n",
      "Epoch: 0041 cost = 0.429757789\n",
      "Validation Error: 0.203125\n",
      "Epoch: 0042 cost = 0.417119024\n",
      "Validation Error: 0.1015625\n",
      "Epoch: 0043 cost = 0.412456569\n",
      "Validation Error: 0.2109375\n",
      "Epoch: 0044 cost = 0.420901854\n",
      "Validation Error: 0.1953125\n",
      "Epoch: 0045 cost = 0.400848046\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0046 cost = 0.406213084\n",
      "Validation Error: 0.1796875\n",
      "Epoch: 0047 cost = 0.397738072\n",
      "Validation Error: 0.1953125\n",
      "Epoch: 0048 cost = 0.393891182\n",
      "Validation Error: 0.1796875\n",
      "Epoch: 0049 cost = 0.387782002\n",
      "Validation Error: 0.203125\n",
      "Epoch: 0050 cost = 0.380354172\n",
      "Validation Error: 0.140625\n",
      "Epoch: 0051 cost = 0.374171919\n",
      "Validation Error: 0.140625\n",
      "Epoch: 0052 cost = 0.377679473\n",
      "Validation Error: 0.1796875\n",
      "Epoch: 0053 cost = 0.376801666\n",
      "Validation Error: 0.1953125\n",
      "Epoch: 0054 cost = 0.367609898\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0055 cost = 0.371920220\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0056 cost = 0.362246977\n",
      "Validation Error: 0.15625\n",
      "Epoch: 0057 cost = 0.356902853\n",
      "Validation Error: 0.109375\n",
      "Epoch: 0058 cost = 0.361129565\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0059 cost = 0.356288390\n",
      "Validation Error: 0.2109375\n",
      "Epoch: 0060 cost = 0.355504386\n",
      "Validation Error: 0.2109375\n",
      "Epoch: 0061 cost = 0.348860893\n",
      "Validation Error: 0.140625\n",
      "Epoch: 0062 cost = 0.348039423\n",
      "Validation Error: 0.2109375\n",
      "Epoch: 0063 cost = 0.347647781\n",
      "Validation Error: 0.1796875\n",
      "Epoch: 0064 cost = 0.343224422\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0065 cost = 0.336966932\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0066 cost = 0.341457845\n",
      "Validation Error: 0.1796875\n",
      "Epoch: 0067 cost = 0.339163877\n",
      "Validation Error: 0.1796875\n",
      "Epoch: 0068 cost = 0.334006616\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0069 cost = 0.325823260\n",
      "Validation Error: 0.1953125\n",
      "Epoch: 0070 cost = 0.330952636\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0071 cost = 0.316941398\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0072 cost = 0.319713872\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0073 cost = 0.321708328\n",
      "Validation Error: 0.2265625\n",
      "Epoch: 0074 cost = 0.314298946\n",
      "Validation Error: 0.15625\n",
      "Epoch: 0075 cost = 0.315839690\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0076 cost = 0.315743567\n",
      "Validation Error: 0.21875\n",
      "Epoch: 0077 cost = 0.310237702\n",
      "Validation Error: 0.1484375\n",
      "Epoch: 0078 cost = 0.308794126\n",
      "Validation Error: 0.1484375\n",
      "Epoch: 0079 cost = 0.313170300\n",
      "Validation Error: 0.1484375\n",
      "Epoch: 0080 cost = 0.310503246\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0081 cost = 0.305869131\n",
      "Validation Error: 0.09375\n",
      "Epoch: 0082 cost = 0.298734556\n",
      "Validation Error: 0.15625\n",
      "Epoch: 0083 cost = 0.295587195\n",
      "Validation Error: 0.15625\n",
      "Epoch: 0084 cost = 0.295374664\n",
      "Validation Error: 0.125\n",
      "Epoch: 0085 cost = 0.294045260\n",
      "Validation Error: 0.1328125\n",
      "Epoch: 0086 cost = 0.289204917\n",
      "Validation Error: 0.1953125\n",
      "Epoch: 0087 cost = 0.291999655\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0088 cost = 0.295081450\n",
      "Validation Error: 0.1171875\n",
      "Epoch: 0089 cost = 0.283759558\n",
      "Validation Error: 0.1796875\n",
      "Epoch: 0090 cost = 0.287213746\n",
      "Validation Error: 0.1796875\n",
      "Epoch: 0091 cost = 0.283543778\n",
      "Validation Error: 0.1328125\n",
      "Epoch: 0092 cost = 0.276828885\n",
      "Validation Error: 0.15625\n",
      "Epoch: 0093 cost = 0.280175331\n",
      "Validation Error: 0.1640625\n",
      "Epoch: 0094 cost = 0.283426716\n",
      "Validation Error: 0.1484375\n",
      "Epoch: 0095 cost = 0.273308129\n",
      "Validation Error: 0.1484375\n",
      "Epoch: 0096 cost = 0.271314865\n",
      "Validation Error: 0.1328125\n",
      "Epoch: 0097 cost = 0.271037641\n",
      "Validation Error: 0.171875\n",
      "Epoch: 0098 cost = 0.274210940\n",
      "Validation Error: 0.2265625\n",
      "Epoch: 0099 cost = 0.272037260\n",
      "Validation Error: 0.1953125\n",
      "Epoch: 0100 cost = 0.269378139\n",
      "Validation Error: 0.1640625\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.828125\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "\n",
    "        with tf.Graph().as_default():\n",
    "\n",
    "            with tf.variable_scope(\"cifar_conv_bn_model\"):\n",
    "\n",
    "                x = tf.placeholder(\"float\", [None, 24, 24, 3])\n",
    "                y = tf.placeholder(\"int32\", [None])\n",
    "                keep_prob = tf.placeholder(tf.float32) # dropout probability\n",
    "                phase_train = tf.placeholder(tf.bool) # training or testing\n",
    "\n",
    "                distorted_images, distorted_labels = distorted_inputs(data_dir, batch_size)\n",
    "                val_images, val_labels = inputs(True, data_dir, batch_size)\n",
    "\n",
    "                output = inference(x, keep_prob, phase_train)\n",
    "\n",
    "                cost = loss(output, y)\n",
    "\n",
    "                global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "                train_op = training(cost, global_step)\n",
    "\n",
    "                eval_op = evaluate(output, y)\n",
    "\n",
    "                summary_op = tf.summary.merge_all()\n",
    "\n",
    "                saver = tf.train.Saver()\n",
    "\n",
    "                sess = tf.Session()\n",
    "\n",
    "                summary_writer = tf.summary.FileWriter(\"conv_cifar_bn_logs/\",\n",
    "                                                       graph_def=sess.graph_def)\n",
    "\n",
    "                \n",
    "                init_op = tf.global_variables_initializer()\n",
    "\n",
    "                sess.run(init_op)\n",
    "                \n",
    "                tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "                # Training cycle\n",
    "                for epoch in range(training_epochs):\n",
    "                    \n",
    "                    avg_cost = 0.\n",
    "                    total_batch = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN/batch_size)\n",
    "                    # Loop over all batches\n",
    "                    for i in range(total_batch):\n",
    "                        # Fit training using batch data\n",
    "                        \n",
    "                        train_x, train_y = sess.run([distorted_images, distorted_labels])\n",
    "                        \n",
    "                        _, new_cost = sess.run([train_op, cost], feed_dict={x: train_x, y: train_y,\n",
    "                                                                            keep_prob: 1,\n",
    "                                                                            phase_train: True})                                            \n",
    "                        # Compute average loss\n",
    "                        avg_cost += new_cost/total_batch\n",
    "                             \n",
    "                    # Display logs per epoch step\n",
    "                    if epoch % display_step == 0:\n",
    "                        print(\"Epoch:\", '%04d' % (epoch+1), \"cost =\", \"{:.9f}\".format(avg_cost))\n",
    "                        \n",
    "                        val_x, val_y = sess.run([val_images, val_labels])\n",
    "                        \n",
    "                        accuracy = sess.run(eval_op, feed_dict={x: val_x, y: val_y,\n",
    "                                                                keep_prob: 1,\n",
    "                                                                phase_train: False})\n",
    "\n",
    "                        print(\"Validation Error:\", (1 - accuracy))\n",
    "\n",
    "                        summary_str = sess.run(summary_op, feed_dict={x: train_x, y: train_y,\n",
    "                                                                      keep_prob: 1,\n",
    "                                                                      phase_train: False})\n",
    "                        summary_writer.add_summary(summary_str, sess.run(global_step))\n",
    "\n",
    "                        saver.save(sess, \"conv_cifar_bn_logs/model-checkpoint\", global_step=global_step)\n",
    "                        \n",
    "                print(\"Optimization Finished!\")\n",
    "                \n",
    "                val_x, val_y = sess.run([val_images, val_labels])\n",
    "                accuracy = sess.run(eval_op, feed_dict={x: val_x, y: val_y,\n",
    "                                                        keep_prob: 1,\n",
    "                                                        phase_train: False})\n",
    "\n",
    "                print(\"Test Accuracy:\", accuracy)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
